# summary:
description: Run `PUT _inference/completion/llama-text-completion` to create a Llama inference endpoint that performs a `chat-completion` task.
method_request: 'PUT _inference/chat-completion/llama-text-chat-completion'
# type: "request"
value: |-
  {
    "service": "llama",
    "service_settings": {
      "url": "http://localhost:8321/v1/openai/v1/chat/completions"
      "api_key": "llama-api-key",
      "model_id": "llama3.2:3b" 
    }
  }
