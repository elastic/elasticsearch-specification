/*
 * Licensed to Elasticsearch B.V. under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch B.V. licenses this file to you under
 * the Apache License, Version 2.0 (the "License"); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

import { Dictionary } from '@spec_utils/Dictionary'
import { AcknowledgedResponseBase } from '@_types/Base'
import { byte, float, integer } from '@_types/Numeric'

/**
 * Sparse Embedding tokens are represented as a dictionary
 * of string to double.
 */
export type SparseVector = Dictionary<string, float>

/**
 * Text Embedding results are represented as Dense Vectors
 * of floats.
 */
export type DenseVector = Array<float>

export class SparseEmbeddingResult {
  embedding: SparseVector
}

/**
 * Text Embedding results containing bytes are represented as Dense
 * Vectors of bytes.
 */
export type DenseByteVector = Array<byte>

/**
 * The text embedding result object for byte representation
 */
export class TextEmbeddingByteResult {
  embedding: DenseByteVector
}

/**
 * The text embedding result object
 */
export class TextEmbeddingResult {
  embedding: DenseVector
}

/**
 * The completion result object
 */
export class CompletionResult {
  result: string
}

/**
 * The rerank result object representing a single ranked document
 * id: the original index of the document in the request
 * score: the score of the document relative to the query
 * text: Optional, the text of the document, if requested
 */
export class RankedDocument {
  index: integer
  score: float
  text?: string
}

/**
 * InferenceResult is an aggregation of mutually exclusive variants
 * @variants container
 */
export class InferenceResult {
  text_embedding_bytes?: Array<TextEmbeddingByteResult>
  text_embedding?: Array<TextEmbeddingResult>
  sparse_embedding?: Array<SparseEmbeddingResult>
  completion?: Array<CompletionResult>
  rerank?: Array<RankedDocument>
}

/**
 * The function the model wants to call.
 */
export class ResultFunctionCall {
  /**
   * The arguments to call the function with in that the model generated in JSON format.
   */
  arguments?: string
  /**
   * The name of the function to call.
   */
  name?: string
}

/**
 * The tool call made by the model.
 */
export class ResultToolCall {
  index: number
  /**
   * The identifier of the tool call.
   */
  id?: string
  /**
   * The function the model wants to call.
   */
  function?: ResultFunctionCall
  /**
   * The type of the tool.
   */
  type?: string
}

export class CompletionDelta {
  /**
   * The contents of the chunked message.
   */
  content?: string
  /**
   * The refusal message.
   */
  refusal?: string
  /**
   * The role of the author of the message.
   */
  role?: string
  /**
   * The tool calls made by the model.
   */
  tool_calls?: Array<ResultToolCall>
}

/**
 * Represent a completion choice returned from a model.
 */
export class CompletionChoice {
  /**
   * The delta generated by the model.
   */
  delta: CompletionDelta
  /**
   * The reason the model stopped generating tokens.
   */
  finish_reason?: string
  /**
   * The index of the choice in the array of choices field.
   */
  index: number
}

/**
 * The token usage statistics for the entire request.
 */
export class Usage {
  /**
   * The number of tokens in the generated completion.
   */
  completion_tokens: number
  /**
   * The number of tokens in the prompt.
   */
  prompt_tokens: number
  /**
   * The sum of completion_tokens and prompt_tokens.
   */
  total_tokens: number
}

/**
 * Respresents the result format for a completion request using the Unified Inference API.
 */
export class UnifiedInferenceResult {
  /**
   * A unique identifier for the chat completion
   */
  id: string
  /**
   * A list of completion choices.
   */
  choices: Array<CompletionChoice>
  /**
   * The model that generated the completion.
   */
  model: string
  /**
   * The object type.
   */
  object: string
  /**
   * The token usage statistics for the entire request.
   */
  usage?: Usage
}

/**
 * Acknowledged response. For dry_run, contains the list of pipelines which reference the inference endpoint
 */
export class DeleteInferenceEndpointResult extends AcknowledgedResponseBase {
  pipelines: Array<string>
}
