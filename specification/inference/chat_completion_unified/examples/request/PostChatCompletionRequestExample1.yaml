summary: A chat completion task
description:
  Run `POST _inference/chat_completion/openai-completion/_stream` to perform a chat completion on the example question
  with streaming.
method_request: 'POST _inference/chat_completion/openai-completion/_stream'
# type: "request"
value: |-
  {
    "model": "gpt-4o",
    "messages": [
        {
            "role": "user",
            "content": "What is Elastic?"
        }
    ]
  }
alternatives:
  - language: Python
    code: |-
      resp = client.inference.chat_completion_unified(
          inference_id="openai-completion",
          chat_completion_request={
              "model": "gpt-4o",
              "messages": [
                  {
                      "role": "user",
                      "content": "What is Elastic?"
                  }
              ]
          },
      )
  - language: JavaScript
    code: |-
      const response = await client.inference.chatCompletionUnified({
        inference_id: "openai-completion",
        chat_completion_request: {
          model: "gpt-4o",
          messages: [
            {
              role: "user",
              content: "What is Elastic?",
            },
          ],
        },
      });
  - language: Ruby
    code: |-
      response = client.inference.chat_completion_unified(
        inference_id: "openai-completion",
        body: {
          "model": "gpt-4o",
          "messages": [
            {
              "role": "user",
              "content": "What is Elastic?"
            }
          ]
        }
      )
  - language: PHP
    code: |-
      $resp = $client->inference()->chatCompletionUnified([
          "inference_id" => "openai-completion",
          "body" => [
              "model" => "gpt-4o",
              "messages" => array(
                  [
                      "role" => "user",
                      "content" => "What is Elastic?",
                  ],
              ),
          ],
      ]);
  - language: curl
    code:
      'curl -X POST -H "Authorization: ApiKey $ELASTIC_API_KEY" -H "Content-Type: application/json" -d
      ''{"model":"gpt-4o","messages":[{"role":"user","content":"What is Elastic?"}]}''
      "$ELASTICSEARCH_URL/_inference/chat_completion/openai-completion/_stream"'
  - language: java
    code: |
      client.inference().chatCompletionUnified(c -> c
      	.inferenceId("openai-completion")
      	.chatCompletionRequest(ch -> ch
      		.messages(m -> m
      			.content(co -> co
      				.string("What is Elastic?")
      			)
      			.role("user")
      		)
      		.model("gpt-4o")
      	)
      );
