summary: A text embedding task
description:
  Run `PUT _inference/text_embedding/azure_openai_embeddings` to create an inference endpoint that performs a
  `text_embedding` task. You do not specify a model, as it is defined already in the Azure OpenAI deployment.
method_request: 'PUT _inference/text_embedding/azure_openai_embeddings'
# type: "request"
value: |-
  {
      "service": "azureopenai",
      "service_settings": {
          "api_key": "Api-Key",
          "resource_name": "Resource-name",
          "deployment_id": "Deployment-id",
          "api_version": "2024-02-01"
      }
  }
alternatives:
  - language: Python
    code: |-
      resp = client.inference.put(
          task_type="text_embedding",
          inference_id="azure_openai_embeddings",
          inference_config={
              "service": "azureopenai",
              "service_settings": {
                  "api_key": "Api-Key",
                  "resource_name": "Resource-name",
                  "deployment_id": "Deployment-id",
                  "api_version": "2024-02-01"
              }
          },
      )
  - language: JavaScript
    code: |-
      const response = await client.inference.put({
        task_type: "text_embedding",
        inference_id: "azure_openai_embeddings",
        inference_config: {
          service: "azureopenai",
          service_settings: {
            api_key: "Api-Key",
            resource_name: "Resource-name",
            deployment_id: "Deployment-id",
            api_version: "2024-02-01",
          },
        },
      });
  - language: Ruby
    code: |-
      response = client.inference.put(
        task_type: "text_embedding",
        inference_id: "azure_openai_embeddings",
        body: {
          "service": "azureopenai",
          "service_settings": {
            "api_key": "Api-Key",
            "resource_name": "Resource-name",
            "deployment_id": "Deployment-id",
            "api_version": "2024-02-01"
          }
        }
      )
  - language: PHP
    code: |-
      $resp = $client->inference()->put([
          "task_type" => "text_embedding",
          "inference_id" => "azure_openai_embeddings",
          "body" => [
              "service" => "azureopenai",
              "service_settings" => [
                  "api_key" => "Api-Key",
                  "resource_name" => "Resource-name",
                  "deployment_id" => "Deployment-id",
                  "api_version" => "2024-02-01",
              ],
          ],
      ]);
  - language: curl
    code:
      "curl -X PUT -H \"Authorization: ApiKey $ELASTIC_API_KEY\" -H \"Content-Type: application/json\" -d
      '{\"service\":\"azureopenai\",\"service_settings\":{\"api_key\":\"Api-Key\",\"resource_name\":\"Resource-name\",\"deployment_\
      id\":\"Deployment-id\",\"api_version\":\"2024-02-01\"}}'
      \"$ELASTICSEARCH_URL/_inference/text_embedding/azure_openai_embeddings\""
  - language: Java
    code: >
      client.inference().put(p -> p
          .inferenceId("azure_openai_embeddings")
          .taskType(TaskType.TextEmbedding)
          .inferenceConfig(i -> i
              .service("azureopenai")
              .serviceSettings(JsonData.fromJson("{\"api_key\":\"Api-Key\",\"resource_name\":\"Resource-name\",\"deployment_id\":\"Deployment-id\",\"api_version\":\"2024-02-01\"}"))
          )
      );
