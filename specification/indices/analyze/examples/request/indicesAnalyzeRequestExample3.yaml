summary: Custom analyzer example 1
method_request: GET /_analyze
description:
  You can test a custom transient analyzer built from tokenizers, token filters, and char filters. Token filters use the
  filter parameter.
# type: request
value:
  tokenizer: keyword
  filter:
    - lowercase
  char_filter:
    - html_strip
  text: 'this is a <b>test</b>'
alternatives:
  - language: Python
    code: |-
      resp = client.indices.analyze(
          tokenizer="keyword",
          filter=[
              "lowercase"
          ],
          char_filter=[
              "html_strip"
          ],
          text="this is a test</b>",
      )
  - language: JavaScript
    code: |-
      const response = await client.indices.analyze({
        tokenizer: "keyword",
        filter: ["lowercase"],
        char_filter: ["html_strip"],
        text: "this is a test</b>",
      });
  - language: Ruby
    code: |-
      response = client.indices.analyze(
        body: {
          "tokenizer": "keyword",
          "filter": [
            "lowercase"
          ],
          "char_filter": [
            "html_strip"
          ],
          "text": "this is a test</b>"
        }
      )
  - language: PHP
    code: |-
      $resp = $client->indices()->analyze([
          "body" => [
              "tokenizer" => "keyword",
              "filter" => array(
                  "lowercase",
              ),
              "char_filter" => array(
                  "html_strip",
              ),
              "text" => "this is a test</b>",
          ],
      ]);
  - language: curl
    code:
      'curl -X GET -H "Authorization: ApiKey $ELASTIC_API_KEY" -H "Content-Type: application/json" -d
      ''{"tokenizer":"keyword","filter":["lowercase"],"char_filter":["html_strip"],"text":"this is a test</b>"}''
      "$ELASTICSEARCH_URL/_analyze"'
  - language: java
    code: |
      client.indices().analyze(a -> a
      	.charFilter(c -> c
      		.name("html_strip")
      	)
      	.filter(f -> f
      		.name("lowercase")
      	)
      	.text("this is a test</b>")
      	.tokenizer(t -> t
      		.name("keyword")
      	)
      );
