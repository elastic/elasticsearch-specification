summary: Custom analyzer example 1
method_request: GET /_analyze
description:
  You can test a custom transient analyzer built from tokenizers, token filters, and char filters. Token filters use the
  filter parameter.
# type: request
value:
  tokenizer: keyword
  filter:
    - lowercase
  char_filter:
    - html_strip
  text: 'this is a <b>test</b>'
alternatives:
  - language: Python
    code: |-
      resp = client.indices.analyze(
          tokenizer="keyword",
          filter=[
              "lowercase"
          ],
          char_filter=[
              "html_strip"
          ],
          text="this is a test</b>",
      )
  - language: JavaScript
    code: |-
      const response = await client.indices.analyze({
        tokenizer: "keyword",
        filter: ["lowercase"],
        char_filter: ["html_strip"],
        text: "this is a test</b>",
      });
  - language: Ruby
    code: |-
      response = client.indices.analyze(
        body: {
          "tokenizer": "keyword",
          "filter": [
            "lowercase"
          ],
          "char_filter": [
            "html_strip"
          ],
          "text": "this is a test</b>"
        }
      )
  - language: PHP
    code: |-
      $resp = $client->indices()->analyze([
          "body" => [
              "tokenizer" => "keyword",
              "filter" => array(
                  "lowercase",
              ),
              "char_filter" => array(
                  "html_strip",
              ),
              "text" => "this is a test</b>",
          ],
      ]);
  - language: curl
    code:
      'curl -X GET -H "Authorization: ApiKey $ELASTIC_API_KEY" -H "Content-Type: application/json" -d
      ''{"tokenizer":"keyword","filter":["lowercase"],"char_filter":["html_strip"],"text":"this is a test</b>"}''
      "$ELASTICSEARCH_URL/_analyze"'
  - language: Java
    code: |
      client.indices().analyze(a -> a
          .charFilter(c -> c
              .name("html_strip")
          )
          .filter(f -> f
              .name("lowercase")
          )
          .text("this is a test</b>")
          .tokenizer(t -> t
              .name("keyword")
          )
      );
