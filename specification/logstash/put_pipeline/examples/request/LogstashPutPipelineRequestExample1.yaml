summary: Create a pipeline
method_request: PUT _logstash/pipeline/my_pipeline
description: Run `PUT _logstash/pipeline/my_pipeline` to create a pipeline.
# type: request
value:
  description: Sample pipeline for illustration purposes
  last_modified: '2021-01-02T02:50:51.250Z'
  pipeline_metadata:
    type: logstash_pipeline
    version: 1
  username: elastic
  pipeline: 'input {}\n filter { grok {} }\n output {}'
  pipeline_settings:
    pipeline.workers: 1
    pipeline.batch.size: 125
    pipeline.batch.delay: 50
    queue.type: memory
    queue.max_bytes: 1gb
    queue.checkpoint.writes: 1024
alternatives:
  - language: Python
    code: |-
      resp = client.logstash.put_pipeline(
          id="my_pipeline",
          pipeline={
              "description": "Sample pipeline for illustration purposes",
              "last_modified": "2021-01-02T02:50:51.250Z",
              "pipeline_metadata": {
                  "type": "logstash_pipeline",
                  "version": 1
              },
              "username": "elastic",
              "pipeline": "input {}\\n filter { grok {} }\\n output {}",
              "pipeline_settings": {
                  "pipeline.workers": 1,
                  "pipeline.batch.size": 125,
                  "pipeline.batch.delay": 50,
                  "queue.type": "memory",
                  "queue.max_bytes": "1gb",
                  "queue.checkpoint.writes": 1024
              }
          },
      )
  - language: JavaScript
    code: |-
      const response = await client.logstash.putPipeline({
        id: "my_pipeline",
        pipeline: {
          description: "Sample pipeline for illustration purposes",
          last_modified: "2021-01-02T02:50:51.250Z",
          pipeline_metadata: {
            type: "logstash_pipeline",
            version: 1,
          },
          username: "elastic",
          pipeline: "input {}\\n filter { grok {} }\\n output {}",
          pipeline_settings: {
            "pipeline.workers": 1,
            "pipeline.batch.size": 125,
            "pipeline.batch.delay": 50,
            "queue.type": "memory",
            "queue.max_bytes": "1gb",
            "queue.checkpoint.writes": 1024,
          },
        },
      });
  - language: Ruby
    code: |-
      response = client.logstash.put_pipeline(
        id: "my_pipeline",
        body: {
          "description": "Sample pipeline for illustration purposes",
          "last_modified": "2021-01-02T02:50:51.250Z",
          "pipeline_metadata": {
            "type": "logstash_pipeline",
            "version": 1
          },
          "username": "elastic",
          "pipeline": "input {}\\n filter { grok {} }\\n output {}",
          "pipeline_settings": {
            "pipeline.workers": 1,
            "pipeline.batch.size": 125,
            "pipeline.batch.delay": 50,
            "queue.type": "memory",
            "queue.max_bytes": "1gb",
            "queue.checkpoint.writes": 1024
          }
        }
      )
  - language: PHP
    code: |-
      $resp = $client->logstash()->putPipeline([
          "id" => "my_pipeline",
          "body" => [
              "description" => "Sample pipeline for illustration purposes",
              "last_modified" => "2021-01-02T02:50:51.250Z",
              "pipeline_metadata" => [
                  "type" => "logstash_pipeline",
                  "version" => 1,
              ],
              "username" => "elastic",
              "pipeline" => "input {}\\n filter { grok {} }\\n output {}",
              "pipeline_settings" => [
                  "pipeline.workers" => 1,
                  "pipeline.batch.size" => 125,
                  "pipeline.batch.delay" => 50,
                  "queue.type" => "memory",
                  "queue.max_bytes" => "1gb",
                  "queue.checkpoint.writes" => 1024,
              ],
          ],
      ]);
  - language: curl
    code:
      "curl -X PUT -H \"Authorization: ApiKey $ELASTIC_API_KEY\" -H \"Content-Type: application/json\" -d '{\"description\":\"Sample
      pipeline for illustration
      purposes\",\"last_modified\":\"2021-01-02T02:50:51.250Z\",\"pipeline_metadata\":{\"type\":\"logstash_pipeline\",\"version\":1\
      },\"username\":\"elastic\",\"pipeline\":\"input {}\\\\n filter { grok {} }\\\\n output
      {}\",\"pipeline_settings\":{\"pipeline.workers\":1,\"pipeline.batch.size\":125,\"pipeline.batch.delay\":50,\"queue.type\":\"m\
      emory\",\"queue.max_bytes\":\"1gb\",\"queue.checkpoint.writes\":1024}}' \"$ELASTICSEARCH_URL/_logstash/pipeline/my_pipeline\""
  - language: Java
    code: |
      client.logstash().putPipeline(p -> p
          .id("my_pipeline")
          .pipeline(pi -> pi
              .description("Sample pipeline for illustration purposes")
              .lastModified(DateTime.of("2021-01-02T02:50:51.250Z"))
              .pipeline("input {}\n filter { grok {} }\n output {}")
              .pipelineMetadata(pip -> pip
                  .type("logstash_pipeline")
                  .version("1")
              )
              .pipelineSettings(pip -> pip
                  .pipelineWorkers(1)
                  .pipelineBatchSize(125)
                  .pipelineBatchDelay(50)
                  .queueType("memory")
                  .queueMaxBytes("1gb")
                  .queueCheckpointWrites(1024)
              )
              .username("elastic")
          )
      );
